{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# Download NLTK stopwords and tokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# File paths\n",
    "train_file_path = \"/Users/dawrynrosario/desktop/IST664/final_project/nlp_project/kagglemoviereviews/corpus/train.tsv\"\n",
    "test_file_path = \"/Users/dawrynrosario/desktop/IST664/final_project/nlp_project/kagglemoviereviews/corpus/test.tsv\"\n",
    "\n",
    "# Step 1: Read in the training and test data\n",
    "train_data = pd.read_csv(train_file_path, sep='\\t')\n",
    "test_data = pd.read_csv(test_file_path, sep='\\t')\n",
    "\n",
    "# Step 2: Preprocessing - Remove stopwords, tokenize, and clean text\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    tokens = word_tokenize(text)  # Tokenize text\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "train_data['ProcessedPhrase'] = train_data['Phrase'].apply(preprocess_text)\n",
    "test_data['ProcessedPhrase'] = test_data['Phrase'].apply(preprocess_text)\n",
    "\n",
    "# Step 3: Split the training data\n",
    "X_train = train_data['ProcessedPhrase']  # Use preprocessed text\n",
    "y_train = train_data['Sentiment']\n",
    "\n",
    "X_test = test_data['ProcessedPhrase']  # Use preprocessed text\n",
    "\n",
    "# Split training data into train and validation sets for evaluation\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Experiment with Bag-of-Words and TF-IDF Vectorizers (including bigram features)\n",
    "# 1. Bag-of-Words with bigram and unigram features\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(1, 2))  # Includes unigrams and bigrams\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train_split)\n",
    "X_val_bow = bow_vectorizer.transform(X_val)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "# 2. TF-IDF with bigram and unigram features\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # Includes unigrams and bigrams\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_split)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Step 5: Train and Evaluate Models\n",
    "# Logistic Regression with Bag-of-Words\n",
    "lr_bow_model = LogisticRegression(max_iter=1000)\n",
    "lr_bow_model.fit(X_train_bow, y_train_split)\n",
    "val_pred_lr_bow = lr_bow_model.predict(X_val_bow)\n",
    "print(\"\\nLogistic Regression with BOW Classification Report:\")\n",
    "print(classification_report(y_val, val_pred_lr_bow))\n",
    "test_pred_lr_bow = lr_bow_model.predict(X_test_bow)\n",
    "\n",
    "# Logistic Regression with TF-IDF\n",
    "lr_tfidf_model = LogisticRegression(max_iter=1000)\n",
    "lr_tfidf_model.fit(X_train_tfidf, y_train_split)\n",
    "val_pred_lr_tfidf = lr_tfidf_model.predict(X_val_tfidf)\n",
    "print(\"\\nLogistic Regression with TF-IDF Classification Report:\")\n",
    "print(classification_report(y_val, val_pred_lr_tfidf))\n",
    "test_pred_lr_tfidf = lr_tfidf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Naive Bayes with Bag-of-Words\n",
    "nb_bow_model = MultinomialNB()\n",
    "nb_bow_model.fit(X_train_bow, y_train_split)\n",
    "val_pred_nb_bow = nb_bow_model.predict(X_val_bow)\n",
    "print(\"\\nNaive Bayes with BOW Classification Report:\")\n",
    "print(classification_report(y_val, val_pred_nb_bow))\n",
    "test_pred_nb_bow = nb_bow_model.predict(X_test_bow)\n",
    "\n",
    "# Naive Bayes with TF-IDF\n",
    "nb_tfidf_model = MultinomialNB()\n",
    "nb_tfidf_model.fit(X_train_tfidf, y_train_split)\n",
    "val_pred_nb_tfidf = nb_tfidf_model.predict(X_val_tfidf)\n",
    "print(\"\\nNaive Bayes with TF-IDF Classification Report:\")\n",
    "print(classification_report(y_val, val_pred_nb_tfidf))\n",
    "test_pred_nb_tfidf = nb_tfidf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Step 6: Save Predictions for Each Model\n",
    "test_data['LR_BOW_Sentiment'] = test_pred_lr_bow\n",
    "test_data['LR_TFIDF_Sentiment'] = test_pred_lr_tfidf\n",
    "test_data['NB_BOW_Sentiment'] = test_pred_nb_bow\n",
    "test_data['NB_TFIDF_Sentiment'] = test_pred_nb_tfidf\n",
    "\n",
    "\n",
    "# Save the predictions to CSV\n",
    "output_file_path = \"/Users/dawrynrosario/desktop/IST664/final_project/nlp_project/kagglemoviereviews/corpus/test_predictions_with_bigrams.csv\"\n",
    "test_data.to_csv(output_file_path, index=False)\n",
    "print(f\"Predictions saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
